{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>...</th>\n",
       "      <th>Single_Parent</th>\n",
       "      <th>Recency_Class</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Total_Spent</th>\n",
       "      <th>Total_Spent_Class</th>\n",
       "      <th>Total_Purchases</th>\n",
       "      <th>Total_Purchases_Class</th>\n",
       "      <th>Total_Visits</th>\n",
       "      <th>Total_Visits_Class</th>\n",
       "      <th>Average_Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1826</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>84835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>104</td>\n",
       "      <td>379</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Recent</td>\n",
       "      <td>Retiree</td>\n",
       "      <td>1190</td>\n",
       "      <td>Average-Spender</td>\n",
       "      <td>15</td>\n",
       "      <td>15-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0-19</td>\n",
       "      <td>602.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>57091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Recent</td>\n",
       "      <td>Senior Citizen</td>\n",
       "      <td>577</td>\n",
       "      <td>Light-Spender</td>\n",
       "      <td>18</td>\n",
       "      <td>15-19</td>\n",
       "      <td>5</td>\n",
       "      <td>0-19</td>\n",
       "      <td>297.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10476</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>67267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Recent</td>\n",
       "      <td>Senior Citizen</td>\n",
       "      <td>251</td>\n",
       "      <td>Cheap-Spender</td>\n",
       "      <td>11</td>\n",
       "      <td>10-14</td>\n",
       "      <td>2</td>\n",
       "      <td>0-19</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1386</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>32474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Recent</td>\n",
       "      <td>Retiree</td>\n",
       "      <td>11</td>\n",
       "      <td>Cheap-Spender</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>7</td>\n",
       "      <td>0-19</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5371</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>21474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Very Recent</td>\n",
       "      <td>Middle-Aged Working Class</td>\n",
       "      <td>91</td>\n",
       "      <td>Cheap-Spender</td>\n",
       "      <td>8</td>\n",
       "      <td>5-9</td>\n",
       "      <td>7</td>\n",
       "      <td>0-19</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID   Education Marital_Status  Income  Kidhome  Teenhome  Recency  \\\n",
       "0   1826  Graduation       Divorced   84835        0         0        0   \n",
       "1      1  Graduation         Single   57091        0         0        0   \n",
       "2  10476  Graduation        Married   67267        0         1        0   \n",
       "3   1386  Graduation       Together   32474        1         1        0   \n",
       "4   5371  Graduation         Single   21474        1         0        0   \n",
       "\n",
       "   MntWines  MntFruits  MntMeatProducts  ...  Single_Parent  Recency_Class  \\\n",
       "0       189        104              379  ...          False    Very Recent   \n",
       "1       464          5               64  ...          False    Very Recent   \n",
       "2       134         11               59  ...          False    Very Recent   \n",
       "3        10          0                1  ...          False    Very Recent   \n",
       "4         6         16               24  ...           True    Very Recent   \n",
       "\n",
       "                   Age_Class  Total_Spent  Total_Spent_Class  Total_Purchases  \\\n",
       "0                    Retiree         1190    Average-Spender               15   \n",
       "1             Senior Citizen          577      Light-Spender               18   \n",
       "2             Senior Citizen          251      Cheap-Spender               11   \n",
       "3                    Retiree           11      Cheap-Spender                4   \n",
       "4  Middle-Aged Working Class           91      Cheap-Spender                8   \n",
       "\n",
       "   Total_Purchases_Class  Total_Visits  Total_Visits_Class  Average_Purchase  \n",
       "0                  15-19             1                0-19             602.5  \n",
       "1                  15-19             5                0-19             297.5  \n",
       "2                  10-14             2                0-19             131.0  \n",
       "3                    0-4             7                0-19               7.5  \n",
       "4                    5-9             7                0-19              49.5  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"feature_engineering.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['ID'])\n",
    "features = pd.get_dummies(features, columns=['Education'], \n",
    "                          prefix='Education')\n",
    "features = pd.get_dummies(features, columns=['Marital_Status'], \n",
    "                          prefix='Marital')\n",
    "features = pd.get_dummies(features, columns=['Recency_Class'], \n",
    "                          prefix='Recency')\n",
    "features = pd.get_dummies(features, columns=['Age_Class'], \n",
    "                          prefix='Age')\n",
    "features = pd.get_dummies(features, \n",
    "                          columns=['Total_Spent_Class'],\n",
    "                           prefix='Total_Spent')\n",
    "features = pd.get_dummies(features, \n",
    "                          columns=['Total_Purchases_Class'], \n",
    "                          prefix='Total_Purchases')\n",
    "features = pd.get_dummies(features, \n",
    "                          columns=['Total_Visits_Class'], \n",
    "                          prefix='Total_Visits')\n",
    "features = pd.get_dummies(features, \n",
    "                          columns=['Family_Classification'], \n",
    "                          prefix='Family_Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(features.columns)) # list down all columns to\n",
    "# be included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.reset_index(inplace=True) # fix bug for encoding of\n",
    "# income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Purchases_5-9</th>\n",
       "      <th>Total_Visits_0-19</th>\n",
       "      <th>Total_Visits_100-119+</th>\n",
       "      <th>Total_Visits_20-39</th>\n",
       "      <th>Total_Visits_40-59</th>\n",
       "      <th>Total_Visits_60-79</th>\n",
       "      <th>Total_Visits_80-99</th>\n",
       "      <th>Family_Classification_Childless</th>\n",
       "      <th>Family_Classification_Medium-Children</th>\n",
       "      <th>Family_Classification_Single-Child</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>65316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>72940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>182</td>\n",
       "      <td>74</td>\n",
       "      <td>298</td>\n",
       "      <td>162</td>\n",
       "      <td>149</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>74716</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>133</td>\n",
       "      <td>27</td>\n",
       "      <td>421</td>\n",
       "      <td>13</td>\n",
       "      <td>195</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>81361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>163</td>\n",
       "      <td>23</td>\n",
       "      <td>424</td>\n",
       "      <td>27</td>\n",
       "      <td>65</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>85072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>494</td>\n",
       "      <td>92</td>\n",
       "      <td>391</td>\n",
       "      <td>194</td>\n",
       "      <td>11</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>83664</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>866</td>\n",
       "      <td>21</td>\n",
       "      <td>151</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>82072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>889</td>\n",
       "      <td>55</td>\n",
       "      <td>685</td>\n",
       "      <td>168</td>\n",
       "      <td>92</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>80950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>525</td>\n",
       "      <td>147</td>\n",
       "      <td>112</td>\n",
       "      <td>219</td>\n",
       "      <td>147</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>37859</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>63967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>387</td>\n",
       "      <td>84</td>\n",
       "      <td>141</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1346 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "1265   65316        1         1       65       112          6   \n",
       "277    72940        0         0       13       182         74   \n",
       "1776   74716        0         1       92       133         27   \n",
       "358    81361        0         0       18       163         23   \n",
       "1816   85072        0         0       94       494         92   \n",
       "...      ...      ...       ...      ...       ...        ...   \n",
       "1130   83664        1         1       57       866         21   \n",
       "1294   82072        0         0       67       889         55   \n",
       "860    80950        0         0       44       525        147   \n",
       "1459   37859        1         2       75        22          1   \n",
       "1126   63967        0         1       57       387         84   \n",
       "\n",
       "      MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  ...  \\\n",
       "1265               92                3                 9            38  ...   \n",
       "277               298              162               149           116  ...   \n",
       "1776              421               13               195            71  ...   \n",
       "358               424               27                65            76  ...   \n",
       "1816              391              194                11           241  ...   \n",
       "...               ...              ...               ...           ...  ...   \n",
       "1130              151               28                21            86  ...   \n",
       "1294              685              168                92           129  ...   \n",
       "860               112              219               147            63  ...   \n",
       "1459                8                2                 1             2  ...   \n",
       "1126              141               73                35           162  ...   \n",
       "\n",
       "      Total_Purchases_5-9  Total_Visits_0-19  Total_Visits_100-119+  \\\n",
       "1265                False              False                  False   \n",
       "277                 False               True                  False   \n",
       "1776                False              False                  False   \n",
       "358                 False               True                  False   \n",
       "1816                False              False                  False   \n",
       "...                   ...                ...                    ...   \n",
       "1130                False              False                  False   \n",
       "1294                False              False                  False   \n",
       "860                 False              False                  False   \n",
       "1459                 True              False                  False   \n",
       "1126                False              False                  False   \n",
       "\n",
       "      Total_Visits_20-39  Total_Visits_40-59  Total_Visits_60-79  \\\n",
       "1265               False               False                True   \n",
       "277                False               False               False   \n",
       "1776               False               False               False   \n",
       "358                False               False               False   \n",
       "1816               False               False               False   \n",
       "...                  ...                 ...                 ...   \n",
       "1130               False               False                True   \n",
       "1294               False               False                True   \n",
       "860                False                True               False   \n",
       "1459               False               False               False   \n",
       "1126               False                True               False   \n",
       "\n",
       "      Total_Visits_80-99  Family_Classification_Childless  \\\n",
       "1265               False                            False   \n",
       "277                False                             True   \n",
       "1776                True                            False   \n",
       "358                False                             True   \n",
       "1816                True                             True   \n",
       "...                  ...                              ...   \n",
       "1130               False                            False   \n",
       "1294               False                             True   \n",
       "860                False                             True   \n",
       "1459                True                            False   \n",
       "1126               False                            False   \n",
       "\n",
       "      Family_Classification_Medium-Children  \\\n",
       "1265                                   True   \n",
       "277                                   False   \n",
       "1776                                  False   \n",
       "358                                   False   \n",
       "1816                                  False   \n",
       "...                                     ...   \n",
       "1130                                   True   \n",
       "1294                                  False   \n",
       "860                                   False   \n",
       "1459                                   True   \n",
       "1126                                  False   \n",
       "\n",
       "      Family_Classification_Single-Child  \n",
       "1265                               False  \n",
       "277                                False  \n",
       "1776                                True  \n",
       "358                                False  \n",
       "1816                               False  \n",
       "...                                  ...  \n",
       "1130                               False  \n",
       "1294                               False  \n",
       "860                                False  \n",
       "1459                               False  \n",
       "1126                                True  \n",
       "\n",
       "[1346 rows x 68 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = features.drop(columns=['Response'], axis=1).iloc[:,1:][\n",
    "    ['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', \n",
    "    'MntFruits', 'MntMeatProducts', 'MntFishProducts', \n",
    "    'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', \n",
    "    'NumWebPurchases', 'NumCatalogPurchases', \n",
    "    'NumStorePurchases', \n",
    "    'NumWebVisitsMonth', \n",
    "    'Complain', 'Age', 'Customer_Enrollment', 'Household', \n",
    "    'Children', 'Single_Parent', 'Total_Spent', \n",
    "    'Total_Purchases', 'Total_Visits', 'Average_Purchase', \n",
    "    'Education_2n Cycle', 'Education_Basic', \n",
    "    'Education_Graduation', 'Education_Master', 'Education_PhD', \n",
    "    'Marital_Divorced', 'Marital_Married', 'Marital_Single', \n",
    "    'Marital_Together', 'Marital_Widow', 'Recency_Infrequent', \n",
    "    'Recency_Less Frequent', 'Recency_Moderate', \n",
    "    'Recency_Recent', 'Recency_Very Recent', \n",
    "    'Age_Middle-Aged Working Class', 'Age_Quinquagenarian', \n",
    "    'Age_Retiree',  'Age_Senior Citizen', \n",
    "    'Age_Very Old Senior Citizen', \n",
    "    'Total_Spent_Above-Average-Spender', \n",
    "    'Total_Spent_Average-Spender', \n",
    "    'Total_Spent_Cheap-Spender', \n",
    "    'Total_Spent_Heavy-Spender', \n",
    "    'Total_Spent_Light-Spender', \n",
    "    'Total_Spent_Very-Heavy-Spender', \n",
    "    'Total_Purchases_0-4', 'Total_Purchases_10-14', \n",
    "    'Total_Purchases_15-19', \n",
    "    'Total_Purchases_20-24', 'Total_Purchases_25-29', \n",
    "    'Total_Purchases_30-34', \n",
    "    'Total_Purchases_35-39+', 'Total_Purchases_5-9', \n",
    "    'Total_Visits_0-19', \n",
    "    'Total_Visits_100-119+', 'Total_Visits_20-39', \n",
    "    'Total_Visits_40-59', \n",
    "    'Total_Visits_60-79', 'Total_Visits_80-99', \n",
    "    'Family_Classification_Childless', \n",
    "    'Family_Classification_Medium-Children', \n",
    "    'Family_Classification_Single-Child']\n",
    "]\n",
    "y = features['Response']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.3, random_state = 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Purchases_5-9</th>\n",
       "      <th>Total_Visits_0-19</th>\n",
       "      <th>Total_Visits_100-119+</th>\n",
       "      <th>Total_Visits_20-39</th>\n",
       "      <th>Total_Visits_40-59</th>\n",
       "      <th>Total_Visits_60-79</th>\n",
       "      <th>Total_Visits_80-99</th>\n",
       "      <th>Family_Classification_Childless</th>\n",
       "      <th>Family_Classification_Medium-Children</th>\n",
       "      <th>Family_Classification_Single-Child</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>44300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>62807</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>526</td>\n",
       "      <td>28</td>\n",
       "      <td>135</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>70287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>295</td>\n",
       "      <td>35</td>\n",
       "      <td>482</td>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>75283</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>733</td>\n",
       "      <td>9</td>\n",
       "      <td>180</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>61839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>155</td>\n",
       "      <td>379</td>\n",
       "      <td>224</td>\n",
       "      <td>17</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>65106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>790</td>\n",
       "      <td>19</td>\n",
       "      <td>133</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>55412</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>71626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>546</td>\n",
       "      <td>72</td>\n",
       "      <td>376</td>\n",
       "      <td>94</td>\n",
       "      <td>145</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>96843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>448</td>\n",
       "      <td>71</td>\n",
       "      <td>951</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>54252</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>178</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "1259   44300        1         1       65        30          0   \n",
       "1623   62807        0         1       83       526         28   \n",
       "611    70287        0         0       30       295         35   \n",
       "514    75283        1         2       26       733          9   \n",
       "413    61839        0         0       20      1000        155   \n",
       "...      ...      ...       ...      ...       ...        ...   \n",
       "1079   65106        0         1       55       790         19   \n",
       "1255   55412        1         1       65        10          5   \n",
       "1831   71626        0         0       94       546         72   \n",
       "1173   96843        0         0       60       448         71   \n",
       "493    54252        1         1       25       178          4   \n",
       "\n",
       "      MntMeatProducts  MntFishProducts  MntSweetProducts  MntGoldProds  ...  \\\n",
       "1259                9                0                 0             3  ...   \n",
       "1623              135               10                21            99  ...   \n",
       "611               482              121               120            40  ...   \n",
       "514               180               12                19            66  ...   \n",
       "413               379              224                17           120  ...   \n",
       "...               ...              ...               ...           ...  ...   \n",
       "1079              133               12                 0            19  ...   \n",
       "1255               28               11                 1             8  ...   \n",
       "1831              376               94               145            72  ...   \n",
       "1173              951               40                17            17  ...   \n",
       "493                26                8                 4            44  ...   \n",
       "\n",
       "      Total_Purchases_5-9  Total_Visits_0-19  Total_Visits_100-119+  \\\n",
       "1259                 True              False                  False   \n",
       "1623                False              False                  False   \n",
       "611                 False              False                  False   \n",
       "514                 False              False                  False   \n",
       "413                 False              False                  False   \n",
       "...                   ...                ...                    ...   \n",
       "1079                False              False                  False   \n",
       "1255                 True              False                  False   \n",
       "1831                False              False                  False   \n",
       "1173                False              False                  False   \n",
       "493                 False              False                  False   \n",
       "\n",
       "      Total_Visits_20-39  Total_Visits_40-59  Total_Visits_60-79  \\\n",
       "1259               False               False                True   \n",
       "1623               False               False               False   \n",
       "611                 True               False               False   \n",
       "514                 True               False               False   \n",
       "413                 True               False               False   \n",
       "...                  ...                 ...                 ...   \n",
       "1079               False               False                True   \n",
       "1255               False               False                True   \n",
       "1831               False               False               False   \n",
       "1173               False               False                True   \n",
       "493                 True               False               False   \n",
       "\n",
       "      Total_Visits_80-99  Family_Classification_Childless  \\\n",
       "1259               False                            False   \n",
       "1623                True                            False   \n",
       "611                False                             True   \n",
       "514                False                            False   \n",
       "413                False                             True   \n",
       "...                  ...                              ...   \n",
       "1079               False                            False   \n",
       "1255               False                            False   \n",
       "1831                True                             True   \n",
       "1173               False                             True   \n",
       "493                False                            False   \n",
       "\n",
       "      Family_Classification_Medium-Children  \\\n",
       "1259                                   True   \n",
       "1623                                  False   \n",
       "611                                   False   \n",
       "514                                    True   \n",
       "413                                   False   \n",
       "...                                     ...   \n",
       "1079                                  False   \n",
       "1255                                   True   \n",
       "1831                                  False   \n",
       "1173                                  False   \n",
       "493                                    True   \n",
       "\n",
       "      Family_Classification_Single-Child  \n",
       "1259                               False  \n",
       "1623                                True  \n",
       "611                                False  \n",
       "514                                False  \n",
       "413                                False  \n",
       "...                                  ...  \n",
       "1079                                True  \n",
       "1255                               False  \n",
       "1831                               False  \n",
       "1173                               False  \n",
       "493                                False  \n",
       "\n",
       "[577 rows x 68 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 280 candidates, totalling 1400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Shaun Padrejuan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'lg__C': 0.01, 'lg__solver': 'lbfgs', 'smote__k_neighbors': 3, 'smote__sampling_strategy': 'not minority'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  \n",
    "    ('lg', LogisticRegression(random_state=42))\n",
    "])\n",
    "parameters = {\n",
    "    'smote__sampling_strategy': ['not majority', \n",
    "    'all', 'auto', 'minority', 'not minority'], \n",
    "    'smote__k_neighbors': [3, 5, 7, 9], \n",
    "    'lg__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "    'lg__solver': ['liblinear', 'lbfgs'] \n",
    "}\n",
    "grid_search = GridSearchCV(pipeline,  \n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'precision',\n",
    "                           cv = 5,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8804\n",
      "Logistic Regression Precision: 0.7200\n",
      "Logistic Regression Recall: 0.2250\n",
      "Logistic Regression F1: 0.3429\n",
      "Logistic Regression AUC: 0.6055\n",
      "Training set precision: 0.7213\n",
      "Test set precision: 0.7200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "smote = SMOTE(sampling_strategy=\n",
    "              best_params['smote__sampling_strategy'], \n",
    "              k_neighbors=best_params['smote__k_neighbors'], \n",
    "              random_state=42)\n",
    "\n",
    "lg = LogisticRegression(C=best_params['lg__C'], \n",
    "                        solver=best_params['lg__solver'], \n",
    "                        random_state=42)\n",
    "\n",
    "pipeline = Pipeline([('smote', smote), ('lg', lg)])\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "lg_pred_train = pipeline.predict(X_train_scaled)\n",
    "lg_pred_test = pipeline.predict(X_test_scaled)\n",
    "\n",
    "lg_acc = accuracy_score(y_test, lg_pred_test)\n",
    "lg_prec = precision_score(y_test, lg_pred_test)\n",
    "lg_rec = recall_score(y_test, lg_pred_test)\n",
    "lg_f1 = f1_score(y_test, lg_pred_test)\n",
    "lg_auc = roc_auc_score(y_test, lg_pred_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %.4f\" % lg_acc)\n",
    "print(\"Logistic Regression Precision: %.4f\" % lg_prec)\n",
    "print(\"Logistic Regression Recall: %.4f\" % lg_rec)\n",
    "print(\"Logistic Regression F1: %.4f\" % lg_f1)\n",
    "print(\"Logistic Regression AUC: %.4f\" % lg_auc)\n",
    "\n",
    "lg_prec_train = precision_score(y_train, lg_pred_train)\n",
    "lg_prec_test = precision_score(y_test, lg_pred_test)\n",
    "\n",
    "print('Training set precision: {:.4f}'.format(lg_prec_train))\n",
    "print('Test set precision: {:.4f}'.format(lg_prec_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[490   7]\n",
      " [ 62  18]]\n",
      "\n",
      "True Positives(TP) =  490\n",
      "\n",
      "True Negatives(TN) =  18\n",
      "\n",
      "False Positives(FP) =  7\n",
      "\n",
      "False Negatives(FN) =  62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "lg_cm = confusion_matrix(y_test, lg_pred_test)\n",
    "print('Confusion matrix\\n\\n', lg_cm)\n",
    "print('\\nTrue Positives(TP) = ', lg_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', lg_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', lg_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', lg_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=lg_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "        index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred_train = nb.predict(X_train)\n",
    "nb_pred_test = nb.predict(X_test)\n",
    "nb_acc = accuracy_score(y_test, nb_pred_test)\n",
    "nb_prec = precision_score(y_test, nb_pred_test)\n",
    "nb_rec = recall_score(y_test, nb_pred_test)\n",
    "nb_f1 = f1_score(y_test, nb_pred_test)\n",
    "nb_auc = roc_auc_score(y_test, nb_pred_test)\n",
    "print(\"Naive Bayes Accuracy: %.4f\" % nb_acc)\n",
    "print(\"Naive Bayes Precision: %.4f\" % nb_prec)\n",
    "print(\"Naive Bayes Recall: %.4f\" % nb_rec)\n",
    "print(\"Naive Bayes F1: %.4f\" % nb_f1)\n",
    "print(\"Naive Bayes AUC: %.4f\" % nb_auc)\n",
    "\n",
    "nb_prec_train = precision_score(y_train, nb_pred_train)\n",
    "nb_prec_test = precision_score(y_test, nb_pred_test)\n",
    "# Check for overfitting\n",
    "print('Training set score: {:.4f}'.format(nb_prec_train))\n",
    "print('Test set score: {:.4f}'.format(nb_prec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cm = confusion_matrix(y_test, nb_pred_test)\n",
    "print('Confusion matrix\\n\\n', nb_cm)\n",
    "print('\\nTrue Positives(TP) = ', nb_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', nb_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', nb_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', nb_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=nb_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "    index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  \n",
    "    ('dt', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "parameters = {\n",
    "    'smote__sampling_strategy': ['not majority', 'all', \n",
    "    'auto', 'minority', 'not minority'],  \n",
    "    'smote__k_neighbors': [3, 5, 7, 9],  \n",
    "    'dt__max_depth': [None, 10, 20],  \n",
    "    'dt__min_samples_split': [2, 5],  \n",
    "    'dt__min_samples_leaf': [1, 2]  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,  \n",
    "                           param_grid=parameters,\n",
    "                           scoring='precision',\n",
    "                           cv=5,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=\n",
    "              best_params['smote__sampling_strategy'], \n",
    "              k_neighbors=best_params['smote__k_neighbors'], \n",
    "              random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=best_params['dt__max_depth'], \n",
    "    min_samples_split=best_params['dt__min_samples_split'], \n",
    "    min_samples_leaf=best_params['dt__min_samples_leaf'],\n",
    "    random_state = 42)  \n",
    "\n",
    "pipeline = Pipeline([('smote', smote), ('dt', dt)])\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "dt_pred_train = pipeline.predict(X_train_scaled)\n",
    "dt_pred_test = pipeline.predict(X_test_scaled)\n",
    "\n",
    "dt_acc = accuracy_score(y_test, dt_pred_test)\n",
    "dt_prec = precision_score(y_test, dt_pred_test)\n",
    "dt_rec = recall_score(y_test, dt_pred_test)\n",
    "dt_f1 = f1_score(y_test, dt_pred_test)\n",
    "dt_auc = roc_auc_score(y_test, dt_pred_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy: %.4f\" % dt_acc)\n",
    "print(\"Decision Tree Precision: %.4f\" % dt_prec)\n",
    "print(\"Decision Tree Recall: %.4f\" % dt_rec)\n",
    "print(\"Decision Tree F1: %.4f\" % dt_f1)\n",
    "print(\"Decision Tree AUC: %.4f\" % dt_auc)\n",
    "\n",
    "dt_prec_train = precision_score(y_train, dt_pred_train)\n",
    "dt_prec_test = precision_score(y_test, dt_pred_test)\n",
    "\n",
    "print('Training set precision: {:.4f}'.format(dt_prec_train))\n",
    "print('Test set precision: {:.4f}'.format(dt_prec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cm = confusion_matrix(y_test, dt_pred_test)\n",
    "print('Confusion matrix\\n\\n', dt_cm)\n",
    "print('\\nTrue Positives(TP) = ', dt_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', dt_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', dt_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', dt_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=dt_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "         index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  \n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "parameters = {\n",
    "    'smote__sampling_strategy': ['not majority', 'all', \n",
    "    'auto', 'minority', 'not minority'], \n",
    "    'smote__k_neighbors': [3, 5, 7, 9],\n",
    "    'knn__n_neighbors': [3, 5, 7, 9], \n",
    "    'knn__weights': ['uniform', 'distance'],  \n",
    "    'knn__p': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,  \n",
    "                           param_grid=parameters,\n",
    "                           scoring='precision',\n",
    "                           cv=5,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=\n",
    "              best_params['smote__sampling_strategy'], \n",
    "              k_neighbors=best_params['smote__k_neighbors'], \n",
    "              random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=\n",
    "                           best_params['knn__n_neighbors'], \n",
    "                           weights=best_params['knn__weights'],\n",
    "                           p=best_params['knn__p'])\n",
    "\n",
    "pipeline = Pipeline([('smote', smote), ('knn', knn)])\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "knn_pred_train = pipeline.predict(X_train_scaled)\n",
    "knn_pred_test = pipeline.predict(X_test_scaled)\n",
    "\n",
    "knn_acc = accuracy_score(y_test, knn_pred_test)\n",
    "knn_prec = precision_score(y_test, knn_pred_test)\n",
    "knn_rec = recall_score(y_test, knn_pred_test)\n",
    "knn_f1 = f1_score(y_test, knn_pred_test)\n",
    "knn_auc = roc_auc_score(y_test, knn_pred_test)\n",
    "\n",
    "print(\"k-Nearest Neighbors Accuracy: %.4f\" % knn_acc)\n",
    "print(\"k-Nearest Neighbors Precision: %.4f\" % knn_prec)\n",
    "print(\"k-Nearest Neighbors Recall: %.4f\" % knn_rec)\n",
    "print(\"k-Nearest Neighbors F1: %.4f\" % knn_f1)\n",
    "print(\"k-Nearest Neighbors AUC: %.4f\" % knn_auc)\n",
    "\n",
    "knn_prec_train = precision_score(y_train, knn_pred_train)\n",
    "knn_prec_test = precision_score(y_test, knn_pred_test)\n",
    "\n",
    "print('Training set precision: {:.4f}'.format(knn_prec_train))\n",
    "print('Test set precision: {:.4f}'.format(knn_prec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cm = confusion_matrix(y_test, knn_pred_test)\n",
    "print('Confusion matrix\\n\\n', knn_cm)\n",
    "print('\\nTrue Positives(TP) = ', knn_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', knn_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', knn_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', knn_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=knn_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "        index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  \n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'smote__sampling_strategy': ['not majority', \n",
    "    'all', 'auto', 'minority', 'not minority'],  \n",
    "    'smote__k_neighbors': [3, 5, 7, 9],  \n",
    "    'svm__C': [0.1, 1],  \n",
    "    'svm__kernel': ['linear', 'rbf'], \n",
    "    'svm__gamma': ['scale']  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,  \n",
    "                           param_grid=parameters,\n",
    "                           scoring='precision',\n",
    "                           cv=5,\n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=\n",
    "              best_params['smote__sampling_strategy'], \n",
    "              k_neighbors=best_params['smote__k_neighbors'], \n",
    "              random_state=42)\n",
    "\n",
    "svm = SVC(C=best_params['svm__C'], \n",
    "          kernel= best_params['svm__kernel'],\n",
    "          gamma=best_params['svm__gamma'], random_state = 42)\n",
    "\n",
    "pipeline = Pipeline([('smote', smote), ('svm', svm)])\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_pred_train = pipeline.predict(X_train_scaled)\n",
    "svm_pred_test = pipeline.predict(X_test_scaled)\n",
    "\n",
    "svm_acc = accuracy_score(y_test, svm_pred_test)\n",
    "svm_prec = precision_score(y_test, svm_pred_test)\n",
    "svm_rec = recall_score(y_test, svm_pred_test)\n",
    "svm_f1 = f1_score(y_test, svm_pred_test)\n",
    "svm_auc = roc_auc_score(y_test, svm_pred_test)\n",
    "\n",
    "print(\"Support Vector Machines Accuracy: %.4f\" % svm_acc)\n",
    "print(\"Support Vector Machines Precision: %.4f\" % svm_prec)\n",
    "print(\"Support Vector Machines Recall: %.4f\" % svm_rec)\n",
    "print(\"Support Vector Machines F1: %.4f\" % svm_f1)\n",
    "print(\"Support Vector Machines AUC: %.4f\" % svm_auc)\n",
    "\n",
    "svm_prec_train = precision_score(y_train, svm_pred_train)\n",
    "svm_prec_test = precision_score(y_test, svm_pred_test)\n",
    "\n",
    "print('Training set precision: {:.4f}'.format(svm_prec_train))\n",
    "print('Test set precision: {:.4f}'.format(svm_prec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cm = confusion_matrix(y_test, svm_pred_test)\n",
    "print('Confusion matrix\\n\\n', svm_cm)\n",
    "print('\\nTrue Positives(TP) = ', svm_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', svm_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', svm_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', svm_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=svm_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "        index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "labels = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC', \n",
    "          'Precision Training Score', 'Precision Test Score']\n",
    "\n",
    "logistic_reg = [lg_acc, lg_prec, lg_rec, lg_f1, lg_auc, \n",
    "                lg_prec_train, lg_prec_test]\n",
    "logistic_reg = [f'{value:.4f}' if isinstance(value, float) \n",
    "                else value for value in logistic_reg]\n",
    "\n",
    "naive_bayes = [nb_acc, nb_prec, nb_rec, nb_f1, nb_auc, \n",
    "               nb_prec_train, nb_prec_test]\n",
    "naive_bayes = [f'{value:.4f}' if isinstance(value, float) \n",
    "               else value for value in naive_bayes]\n",
    "\n",
    "decision_tree = [dt_acc, dt_prec, dt_rec, dt_f1, dt_auc, \n",
    "                 dt_prec_train, dt_prec_test]\n",
    "decision_tree = [f'{value:.4f}' if isinstance(value, float) \n",
    "                 else value for value in decision_tree]\n",
    "\n",
    "k_nearest = [knn_acc, knn_prec, knn_rec, knn_f1, knn_auc, \n",
    "             knn_prec_train, knn_prec_test] \n",
    "k_nearest = [f'{value:.4f}' if isinstance(value, float) \n",
    "             else value for value in k_nearest]\n",
    "\n",
    "support_vector = [svm_acc, svm_prec, svm_rec, svm_f1, svm_auc, \n",
    "                  svm_prec_train, svm_prec_test]\n",
    "support_vector = [f'{value:.4f}' if isinstance(value, float) \n",
    "                  else value for value in support_vector]\n",
    "\n",
    "variables = [\n",
    "    ('Logistic Regression', logistic_reg),\n",
    "    ('Naive Bayes', naive_bayes),\n",
    "    ('Decision Tree', decision_tree),\n",
    "    ('k-Nearest Neighbors', k_nearest),\n",
    "    ('Support Vector Machines', support_vector)\n",
    "]\n",
    "table = PrettyTable()\n",
    "table.add_column('Algorithm', labels)\n",
    "table.add_column('Logistic Regression', logistic_reg)\n",
    "table.add_column('Naive Bayes', naive_bayes)\n",
    "table.add_column('Decision Tree', decision_tree)\n",
    "table.add_column('k-Nearest Neighbors', k_nearest)\n",
    "table.add_column('Support Vector Machines', support_vector)\n",
    "table.align = 'l'\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
