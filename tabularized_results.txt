X = features.drop(columns=['Response'], axis=1).iloc[:,1:][['Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits', 
                                                 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 
                                                 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 
                                                 'NumStorePurchases', 'NumWebVisitsMonth', 'Complain', 
                                                 'Age', 'Customer_Enrollment', 'Household', 'Total_Spent', 
                                                 'Total_Purchases', 'Total_Visits', 'Average_Purchase', 
                                                 'Education_2n Cycle', 'Education_Basic', 'Education_Graduation', 
                                                 'Education_Master', 'Education_PhD', 'Marital_Divorced', 
                                                 'Marital_Married', 'Marital_Single', 'Marital_Together', 'Marital_Widow',
                                                 'Income']]

Use RobustScaler instead of StandardScaler
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Algorithm                | Logistic Regression | Naive Bayes | Decision Tree | k-Nearest Neighbors | Support Vector Machines |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Accuracy                 | 0.8925              | 0.7279      | 0.8163        | 0.8250              | 0.8977                  |
| Precision                | 0.6607              | 0.2579      | 0.3917        | 0.4019              | 0.6842                  |
| Recall                   | 0.4625              | 0.5125      | 0.5875        | 0.5375              | 0.4875                  |
| F1                       | 0.5441              | 0.3431      | 0.4700        | 0.4599              | 0.5693                  |
| AUC                      | 0.7121              | 0.6375      | 0.7203        | 0.7044              | 0.7256                  |
| Precision Training Score | 0.9548              | 0.7081      | 0.9786        | 0.9362              | 0.9544                  |
| Precision Test Score     | 0.6607              | 0.2579      | 0.3917        | 0.4019              | 0.6842                  |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+

If we used all features
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Algorithm                | Logistic Regression | Naive Bayes | Decision Tree | k-Nearest Neighbors | Support Vector Machines |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Accuracy                 | 0.8631              | 0.7418      | 0.7834        | 0.8284              | 0.8752                  |
| Precision                | 0.5091              | 0.2745      | 0.3109        | 0.3733              | 0.6250                  |
| Recall                   | 0.3500              | 0.5250      | 0.4625        | 0.3500              | 0.2500                  |
| F1                       | 0.4148              | 0.3605      | 0.3719        | 0.3613              | 0.3571                  |
| AUC                      | 0.6478              | 0.6508      | 0.6488        | 0.6277              | 0.6129                  |
| Precision Training Score | 0.9351              | 0.7260      | 0.9839        | 1.0000              | 0.9831                  |
| Precision Test Score     | 0.5091              | 0.2745      | 0.3109        | 0.3733              | 0.6250                  |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
RobustScaler
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Algorithm                | Logistic Regression | Naive Bayes | Decision Tree | k-Nearest Neighbors | Support Vector Machines |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Accuracy                 | 0.8579              | 0.7418      | 0.7920        | 0.7920              | 0.8735                  |
| Precision                | 0.4828              | 0.2745      | 0.3246        | 0.3039              | 0.6207                  |
| Recall                   | 0.3500              | 0.5250      | 0.4625        | 0.3875              | 0.2250                  |
| F1                       | 0.4058              | 0.3605      | 0.3814        | 0.3407              | 0.3303                  |
| AUC                      | 0.6448              | 0.6508      | 0.6538        | 0.6223              | 0.6014                  |
| Precision Training Score | 0.9333              | 0.7260      | 0.9839        | 1.0000              | 0.9816                  |
| Precision Test Score     | 0.4828              | 0.2745      | 0.3246        | 0.3039              | 0.6207                  |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+

Added more features (SMOTE and StandardScaler)
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Algorithm                | Logistic Regression | Naive Bayes | Decision Tree | k-Nearest Neighbors | Support Vector Machines |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Accuracy                 | 0.8873              | 0.7522      | 0.8094        | 0.8406              | 0.8856                  |
| Precision                | 0.6364              | 0.2734      | 0.3077        | 0.4062              | 0.6842                  |
| Recall                   | 0.4375              | 0.4750      | 0.3000        | 0.3250              | 0.3250                  |
| F1                       | 0.5185              | 0.3470      | 0.3038        | 0.3611              | 0.4407                  |
| AUC                      | 0.6986              | 0.6359      | 0.5957        | 0.6243              | 0.6504                  |
| Precision Training Score | 0.9556              | 0.7373      | 0.9946        | 0.9672              | 0.9840                  |
| Precision Test Score     | 0.6364              | 0.2734      | 0.3077        | 0.4062              | 0.6842                  |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+

Without oversampling
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Algorithm                | Logistic Regression | Naive Bayes | Decision Tree | k-Nearest Neighbors | Support Vector Machines |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+
| Accuracy                 | 0.8804              | 0.7522      | 0.8579        | 0.8683              | 0.8735                  |
| Precision                | 0.7200              | 0.2797      | 0.4000        | 0.5769              | 0.6522                  |
| Recall                   | 0.2250              | 0.5000      | 0.0500        | 0.1875              | 0.1875                  |
| F1                       | 0.3429              | 0.3587      | 0.0889        | 0.2830              | 0.2913                  |
| AUC                      | 0.6055              | 0.6464      | 0.5190        | 0.5827              | 0.5857                  |
| Precision Training Score | 0.7213              | 0.3087      | 0.9565        | 0.7391              | 0.9322                  |
| Precision Test Score     | 0.7200              | 0.2797      | 0.4000        | 0.5769              | 0.6522                  |
+--------------------------+---------------------+-------------+---------------+---------------------+-------------------------+