# Initial
Accuracy: 0.8512
Precision: 0.5000
Recall: 0.0200
F1: 0.0385
AUC: 0.5083

# Changed Date Enrolment to Year only

# Removed Entries with Year of Birth earlier than 1940
Accuracy: 0.8542
Precision: 1.0000
Recall: 0.0200
F1: 0.0392
AUC: 0.5100

# Removed Dt_Customer
Accuracy: 0.8571
Precision: 0.8333
Recall: 0.0500
F1: 0.0943
AUC: 0.5241

# Tried Different Models for baseline comparison

## Naive Bayes
Accuracy: 0.7679
Precision: 0.3028
Recall: 0.4300
F1: 0.3554
AUC: 0.6285

## Decision Trees
Accuracy: 0.7887
Precision: 0.3158
Recall: 0.3600
F1: 0.3364
AUC: 0.6118

## SVC
Accuracy: 0.8512
Precision: 0.5000
Recall: 0.0300
F1: 0.0566
AUC: 0.5124

## KNeighbors k=25
Accuracy: 0.8512
Precision: 0.5000
Recall: 0.0300
F1: 0.0566
AUC: 0.5124

# Back to Logistic

## Used MinMaxScaler just for some comparison
Accuracy: 0.8571
Precision: 1.0000
Recall: 0.0400
F1: 0.0769
AUC: 0.5200

## Back to StandardScaler ++ one_hot_encode Education and Marital Status
Accuracy: 0.8571
Precision: 0.8333
Recall: 0.0500
F1: 0.0943
AUC: 0.5241

## Filled Missing Income using the median of Similar combination of Education and Marital_Status
### No Effect

## Dropped Income Outliers using std method
### threshold = 1
Accuracy: 0.8783 1
Precision: 0.2500 3
Recall: 0.0172 3
F1: 0.0323 3
AUC: 0.5052 3

### threshold = 3
Accuracy: 0.8535 2
Precision: 0.5714 1
Recall: 0.0800 2
F1: 0.1404 2
AUC: 0.5347 2

### threshold = 2
Accuracy: 0.8533 3
Precision: 0.5625 2
Recall: 0.0900 1
F1: 0.1552  1
AUC: 0.5388 1

## Continued with threshold=2 as it has the lowest sum based on ranking

## Added WebPurchase incentive (WebTransactions) and removed WebPurchases & NumWebVistsMonth
Accuracy: 0.8623
Precision: 0.6667
Recall: 0.1600
F1: 0.2581
AUC: 0.5730

## Added SingleParent Indicator and Combined Kidhome and Teenhome as TotalChildren
Accuracy: 0.8638
Precision: 0.7143
Recall: 0.1500
F1: 0.2479
AUC: 0.5697

## Created RecencyRelevance that ratios the recency to the total Mnt and removed Recency and all Mnt
Accuracy: 0.8593
Precision: 0.5789
Recall: 0.2200
F1: 0.3188
AUC: 0.5959

## Deleted Dupes it would be statistically impossible for two or more  Different
## people to have lived the same grocery life and life in general (Forgot to retain ID, fix next time)
Accuracy: 0.8436
Precision: 0.4583
Recall: 0.1170
F1: 0.1864
AUC: 0.5460

## Changed test size to 20%
Accuracy: 0.8484
Precision: 0.5000
Recall: 0.1613
F1: 0.2439
AUC: 0.5662

# Created a table comprising of all five models for comparison
Found on Gdocs for better reference
    Classifier	            Accuracy	Precision	Recall	F1 Score	AUC	    Training	Test
0	Logistic Regression	    0.8484	    0.5000	    0.1613	0.2439	    0.5662	0.8564	    0.8411
1	Gaussian Naive Bayes	0.7897	    0.3636	    0.5161	0.4267	    0.6774	0.7696	    0.1516
2	Decision Tree	        0.8435	    0.3333	    0.0323	0.0588	    0.5104	0.8594	    0.1663
3	SVC	                    0.8460	    0.4000	    0.0323	0.0597	    0.5118	0.8594	    0.8484
4	K Nearest Neighbors	    0.8362	    0.3810	    0.1290	0.1928	    0.5458	0.8729	    0.4230

# Trying different Nomarlization Techniques
## MinMaxScaler poor results
## RobustScaler with STD method
Accuracy: 0.7311
Precision: 0.2966
Recall: 0.5645
F1: 0.3889
AUC: 0.6627

## RobustScaler with IQR method same with StandardScaler with IQR
Accuracy: 0.8537
Precision: 0.5882
Recall: 0.1587
F1: 0.2500
AUC: 0.5693

# For timeline Purposes, Mali pagkakaintindi
# Base - Removed Dupes, StandardScaler, Logistic Regression
Accuracy: 0.8460
Precision: 0.4444
Recall: 0.0645
F1: 0.1127
AUC: 0.5251

# With All Columns; 
    DtCustomer converted to Year only; 
    Populated Income with Median with Same Education and Marital Status;
    Removed Entries with year of Birth earlier than 1940;
Accuracy: 0.8516
Precision: 0.6667
Recall: 0.0635
F1: 0.1159
AUC: 0.5289

# IQR method on Income
Accuracy: 0.8732
Precision: 0.6571
Recall: 0.3651
F1: 0.4694
AUC: 0.6652

# STD method on Income
Accuracy: 0.8875
Precision: 0.7500
Recall: 0.3871
F1: 0.5106
AUC: 0.6820

# WebTransactions & Removed WebPurchase and NumWebVistsMonth
Accuracy: 0.8826
Precision: 0.7333
Recall: 0.3548
F1: 0.4783
AUC: 0.6659

Training set score: 0.8661
Test set score: 0.1516

# SVC, 
Accuracy: 0.8631
Precision: 0.6875
Recall: 0.1774
F1: 0.2821
AUC: 0.5815

Training set score: 0.8863
Test set score: 0.8484

# LR with empty Income set to 0
Accuracy: 0.8851
Precision: 0.7419
Recall: 0.3710
F1: 0.4946
AUC: 0.6740

Training set score: 0.8661
Test set score: 0.1711
# 
# 
# 
# 
# 