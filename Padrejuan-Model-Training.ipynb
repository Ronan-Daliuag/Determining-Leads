{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"feature_engineering.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['ID'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also encode Education and Marital_Status\n",
    "features = pd.get_dummies(features, columns=['Education'], prefix='Education')\n",
    "features = pd.get_dummies(features, columns=['Marital_Status'], prefix='Marital')\n",
    "features = pd.get_dummies(features, columns=['Recency_Class'], prefix='Recency')\n",
    "features = pd.get_dummies(features, columns=['Age_Class'], prefix='Age')\n",
    "features = pd.get_dummies(features, columns=['Total_Spent_Class'], prefix='Total_Spent')\n",
    "features = pd.get_dummies(features, columns=['Total_Purchases_Class'], prefix='Total_Purchases')\n",
    "features = pd.get_dummies(features, columns=['Total_Visits_Class'], prefix='Total_Visits')\n",
    "features = pd.get_dummies(features, columns=['Family_Classification'], prefix='Family_Classification')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(features.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = features.drop(columns=['Response'], axis=1).iloc[:,1:][['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits', \n",
    "                                                            'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', \n",
    "                                                            'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', \n",
    "                                                            'NumStorePurchases', 'NumWebVisitsMonth', \n",
    "                                                            'Complain', 'Age', 'Customer_Enrollment', 'Household', \n",
    "                                                            'Children', 'Single_Parent', 'Total_Spent', 'Total_Purchases', \n",
    "                                                            'Total_Visits', 'Average_Purchase', 'Education_2n Cycle', 'Education_Basic', \n",
    "                                                            'Education_Graduation', 'Education_Master', 'Education_PhD', \n",
    "                                                            'Marital_Divorced', 'Marital_Married', 'Marital_Single', 'Marital_Together', \n",
    "                                                            'Marital_Widow', 'Recency_Infrequent', 'Recency_Less Frequent', \n",
    "                                                            'Recency_Moderate', 'Recency_Recent', 'Recency_Very Recent', \n",
    "                                                            'Age_Middle-Aged Working Class', 'Age_Quinquagenarian', 'Age_Retiree', \n",
    "                                                            'Age_Senior Citizen', 'Age_Very Old Senior Citizen', \n",
    "                                                            'Total_Spent_Above-Average-Spender', 'Total_Spent_Average-Spender', \n",
    "                                                            'Total_Spent_Cheap-Spender', 'Total_Spent_Heavy-Spender', \n",
    "                                                            'Total_Spent_Light-Spender', 'Total_Spent_Very-Heavy-Spender', \n",
    "                                                            'Total_Purchases_0-4', 'Total_Purchases_10-14', 'Total_Purchases_15-19', \n",
    "                                                            'Total_Purchases_20-24', 'Total_Purchases_25-29', 'Total_Purchases_30-34', \n",
    "                                                            'Total_Purchases_35-39+', 'Total_Purchases_5-9', 'Total_Visits_0-19', \n",
    "                                                            'Total_Visits_100-119+', 'Total_Visits_20-39', 'Total_Visits_40-59', \n",
    "                                                            'Total_Visits_60-79', 'Total_Visits_80-99', 'Family_Classification_Childless', \n",
    "                                                            'Family_Classification_Medium-Children', 'Family_Classification_Single-Child']\n",
    "]\n",
    "# X = features.drop(columns=['Response'], axis = 1)\n",
    "y = features['Response']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  \n",
    "    ('lg', LogisticRegression(random_state=42))\n",
    "])\n",
    "parameters = {\n",
    "    'smote__sampling_strategy': ['not majority', 'all', 'auto', 'minority', 'not minority'], \n",
    "    'smote__k_neighbors': [3, 5, 7, 9], \n",
    "    'lg__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "    'lg__solver': ['liblinear', 'lbfgs'] \n",
    "}\n",
    "grid_search = GridSearchCV(pipeline,  \n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'precision',\n",
    "                           cv = 5,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "smote = SMOTE(sampling_strategy=best_params['smote__sampling_strategy'], \n",
    "              k_neighbors=best_params['smote__k_neighbors'], \n",
    "              random_state=42)\n",
    "\n",
    "lg = LogisticRegression(C=best_params['lg__C'], \n",
    "                        solver=best_params['lg__solver'], \n",
    "                        random_state=42)\n",
    "\n",
    "pipeline = Pipeline([('smote', smote), ('lg', lg)])\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "lg_pred_train = pipeline.predict(X_train_scaled)\n",
    "lg_pred_test = pipeline.predict(X_test_scaled)\n",
    "\n",
    "lg_acc = accuracy_score(y_test, lg_pred_test)\n",
    "lg_prec = precision_score(y_test, lg_pred_test)\n",
    "lg_rec = recall_score(y_test, lg_pred_test)\n",
    "lg_f1 = f1_score(y_test, lg_pred_test)\n",
    "lg_auc = roc_auc_score(y_test, lg_pred_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %.4f\" % lg_acc)\n",
    "print(\"Logistic Regression Precision: %.4f\" % lg_prec)\n",
    "print(\"Logistic Regression Recall: %.4f\" % lg_rec)\n",
    "print(\"Logistic Regression F1: %.4f\" % lg_f1)\n",
    "print(\"Logistic Regression AUC: %.4f\" % lg_auc)\n",
    "\n",
    "lg_prec_train = precision_score(y_train, lg_pred_train)\n",
    "lg_prec_test = precision_score(y_test, lg_pred_test)\n",
    "\n",
    "print('Training set precision: {:.4f}'.format(lg_prec_train))\n",
    "print('Test set precision: {:.4f}'.format(lg_prec_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "lg_cm = confusion_matrix(y_test, lg_pred_test)\n",
    "print('Confusion matrix\\n\\n', lg_cm)\n",
    "print('\\nTrue Positives(TP) = ', lg_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', lg_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', lg_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', lg_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=lg_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "                                 index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred_train = nb.predict(X_train)\n",
    "nb_pred_test = nb.predict(X_test)\n",
    "nb_acc = accuracy_score(y_test, nb_pred_test)\n",
    "nb_prec = precision_score(y_test, nb_pred_test)\n",
    "nb_rec = recall_score(y_test, nb_pred_test)\n",
    "nb_f1 = f1_score(y_test, nb_pred_test)\n",
    "nb_auc = roc_auc_score(y_test, nb_pred_test)\n",
    "print(\"Naive Bayes Accuracy: %.4f\" % nb_acc)\n",
    "print(\"Naive Bayes Precision: %.4f\" % nb_prec)\n",
    "print(\"Naive Bayes Recall: %.4f\" % nb_rec)\n",
    "print(\"Naive Bayes F1: %.4f\" % nb_f1)\n",
    "print(\"Naive Bayes AUC: %.4f\" % nb_auc)\n",
    "\n",
    "nb_prec_train = precision_score(y_train, nb_pred_train)\n",
    "nb_prec_test = precision_score(y_test, nb_pred_test)\n",
    "# Check for overfitting\n",
    "print('Training set score: {:.4f}'.format(nb_prec_train))\n",
    "print('Test set score: {:.4f}'.format(nb_prec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cm = confusion_matrix(y_test, nb_pred_test)\n",
    "print('Confusion matrix\\n\\n', nb_cm)\n",
    "print('\\nTrue Positives(TP) = ', nb_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', nb_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', nb_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', nb_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=nb_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "                                 index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  \n",
    "    ('dt', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "parameters = {\n",
    "    'smote__sampling_strategy': ['not majority', 'all', 'auto', 'minority', 'not minority'],  \n",
    "    'smote__k_neighbors': [3, 5, 7, 9],  \n",
    "    'dt__max_depth': [None, 10, 20],  \n",
    "    'dt__min_samples_split': [2, 5],  \n",
    "    'dt__min_samples_leaf': [1, 2]  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,  \n",
    "                           param_grid=parameters,\n",
    "                           scoring='precision',\n",
    "                           cv=5,\n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "\n",
    "smote = SMOTE(sampling_strategy=best_params['smote__sampling_strategy'], \n",
    "              k_neighbors=best_params['smote__k_neighbors'], \n",
    "              random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=best_params['dt__max_depth'], \n",
    "                            min_samples_split=best_params['dt__min_samples_split'], \n",
    "                            min_samples_leaf=best_params['dt__min_samples_leaf'],\n",
    "                            random_state = 42)  \n",
    "\n",
    "pipeline = Pipeline([('smote', smote), ('dt', dt)])\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "dt_pred_train = pipeline.predict(X_train_scaled)\n",
    "dt_pred_test = pipeline.predict(X_test_scaled)\n",
    "\n",
    "dt_acc = accuracy_score(y_test, dt_pred_test)\n",
    "dt_prec = precision_score(y_test, dt_pred_test)\n",
    "dt_rec = recall_score(y_test, dt_pred_test)\n",
    "dt_f1 = f1_score(y_test, dt_pred_test)\n",
    "dt_auc = roc_auc_score(y_test, dt_pred_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy: %.4f\" % dt_acc)\n",
    "print(\"Decision Tree Precision: %.4f\" % dt_prec)\n",
    "print(\"Decision Tree Recall: %.4f\" % dt_rec)\n",
    "print(\"Decision Tree F1: %.4f\" % dt_f1)\n",
    "print(\"Decision Tree AUC: %.4f\" % dt_auc)\n",
    "\n",
    "dt_prec_train = precision_score(y_train, dt_pred_train)\n",
    "dt_prec_test = precision_score(y_test, dt_pred_test)\n",
    "\n",
    "print('Training set precision: {:.4f}'.format(dt_prec_train))\n",
    "print('Test set precision: {:.4f}'.format(dt_prec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cm = confusion_matrix(y_test, dt_pred_test)\n",
    "print('Confusion matrix\\n\\n', dt_cm)\n",
    "print('\\nTrue Positives(TP) = ', dt_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', dt_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', dt_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', dt_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=dt_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "                                 index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  \n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "parameters = {\n",
    "    'smote__sampling_strategy': ['not majority', 'all', 'auto', 'minority', 'not minority'], \n",
    "    'smote__k_neighbors': [3, 5, 7, 9],\n",
    "    'knn__n_neighbors': [3, 5, 7, 9], \n",
    "    'knn__weights': ['uniform', 'distance'],  \n",
    "    'knn__p': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,  \n",
    "                           param_grid=parameters,\n",
    "                           scoring='precision',\n",
    "                           cv=5,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "\n",
    "smote = SMOTE(sampling_strategy=best_params['smote__sampling_strategy'], \n",
    "              k_neighbors=best_params['smote__k_neighbors'], \n",
    "              random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_params['knn__n_neighbors'], weights=best_params['knn__weights'],\n",
    "                           p=best_params['knn__p'])\n",
    "\n",
    "pipeline = Pipeline([('smote', smote), ('knn', knn)])\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "knn_pred_train = pipeline.predict(X_train_scaled)\n",
    "knn_pred_test = pipeline.predict(X_test_scaled)\n",
    "\n",
    "knn_acc = accuracy_score(y_test, knn_pred_test)\n",
    "knn_prec = precision_score(y_test, knn_pred_test)\n",
    "knn_rec = recall_score(y_test, knn_pred_test)\n",
    "knn_f1 = f1_score(y_test, knn_pred_test)\n",
    "knn_auc = roc_auc_score(y_test, knn_pred_test)\n",
    "\n",
    "print(\"k-Nearest Neighbors Accuracy: %.4f\" % knn_acc)\n",
    "print(\"k-Nearest Neighbors Precision: %.4f\" % knn_prec)\n",
    "print(\"k-Nearest Neighbors Recall: %.4f\" % knn_rec)\n",
    "print(\"k-Nearest Neighbors F1: %.4f\" % knn_f1)\n",
    "print(\"k-Nearest Neighbors AUC: %.4f\" % knn_auc)\n",
    "\n",
    "knn_prec_train = precision_score(y_train, knn_pred_train)\n",
    "knn_prec_test = precision_score(y_test, knn_pred_test)\n",
    "\n",
    "print('Training set precision: {:.4f}'.format(knn_prec_train))\n",
    "print('Test set precision: {:.4f}'.format(knn_prec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cm = confusion_matrix(y_test, knn_pred_test)\n",
    "print('Confusion matrix\\n\\n', knn_cm)\n",
    "print('\\nTrue Positives(TP) = ', knn_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', knn_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', knn_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', knn_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=knn_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "                                 index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  \n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'smote__sampling_strategy': ['not majority', 'all', 'auto', 'minority', 'not minority'],  \n",
    "    'smote__k_neighbors': [3, 5, 7, 9],  \n",
    "    'svm__C': [0.1, 1],  \n",
    "    'svm__kernel': ['linear', 'rbf'], \n",
    "    'svm__gamma': ['scale']  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,  \n",
    "                           param_grid=parameters,\n",
    "                           scoring='precision',\n",
    "                           cv=5,\n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=best_params['smote__sampling_strategy'], \n",
    "              k_neighbors=best_params['smote__k_neighbors'], \n",
    "              random_state=42)\n",
    "\n",
    "svm = SVC(C=best_params['svm__C'], kernel = best_params['svm__kernel'],\n",
    "          gamma=best_params['svm__gamma'], random_state = 42)\n",
    "\n",
    "pipeline = Pipeline([('smote', smote), ('svm', svm)])\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_pred_train = pipeline.predict(X_train_scaled)\n",
    "svm_pred_test = pipeline.predict(X_test_scaled)\n",
    "\n",
    "svm_acc = accuracy_score(y_test, svm_pred_test)\n",
    "svm_prec = precision_score(y_test, svm_pred_test)\n",
    "svm_rec = recall_score(y_test, svm_pred_test)\n",
    "svm_f1 = f1_score(y_test, svm_pred_test)\n",
    "svm_auc = roc_auc_score(y_test, svm_pred_test)\n",
    "\n",
    "print(\"Support Vector Machines Accuracy: %.4f\" % svm_acc)\n",
    "print(\"Support Vector Machines Precision: %.4f\" % svm_prec)\n",
    "print(\"Support Vector Machines Recall: %.4f\" % svm_rec)\n",
    "print(\"Support Vector Machines F1: %.4f\" % svm_f1)\n",
    "print(\"Support Vector Machines AUC: %.4f\" % svm_auc)\n",
    "\n",
    "svm_prec_train = precision_score(y_train, svm_pred_train)\n",
    "svm_prec_test = precision_score(y_test, svm_pred_test)\n",
    "\n",
    "print('Training set precision: {:.4f}'.format(svm_prec_train))\n",
    "print('Test set precision: {:.4f}'.format(svm_prec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cm = confusion_matrix(y_test, svm_pred_test)\n",
    "print('Confusion matrix\\n\\n', svm_cm)\n",
    "print('\\nTrue Positives(TP) = ', svm_cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', svm_cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', svm_cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', svm_cm[1,0])\n",
    "cm_matrix = pd.DataFrame(data=svm_cm, columns=['Actual Positive', 'Actual Negative'], \n",
    "                                 index=['Predict Positive', 'Predict Negative'])\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "labels = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC', 'Precision Training Score', 'Precision Test Score']\n",
    "\n",
    "logistic_reg = [lg_acc, lg_prec, lg_rec, lg_f1, lg_auc, lg_prec_train, lg_prec_test]\n",
    "logistic_reg = [f'{value:.4f}' if isinstance(value, float) else value for value in logistic_reg]\n",
    "\n",
    "naive_bayes = [nb_acc, nb_prec, nb_rec, nb_f1, nb_auc, nb_prec_train, nb_prec_test]\n",
    "naive_bayes = [f'{value:.4f}' if isinstance(value, float) else value for value in naive_bayes]\n",
    "\n",
    "decision_tree = [dt_acc, dt_prec, dt_rec, dt_f1, dt_auc, dt_prec_train, dt_prec_test]\n",
    "decision_tree = [f'{value:.4f}' if isinstance(value, float) else value for value in decision_tree]\n",
    "\n",
    "k_nearest = [knn_acc, knn_prec, knn_rec, knn_f1, knn_auc, knn_prec_train, knn_prec_test] \n",
    "k_nearest = [f'{value:.4f}' if isinstance(value, float) else value for value in k_nearest]\n",
    "\n",
    "support_vector = [svm_acc, svm_prec, svm_rec, svm_f1, svm_auc, svm_prec_train, svm_prec_test]\n",
    "support_vector = [f'{value:.4f}' if isinstance(value, float) else value for value in support_vector]\n",
    "\n",
    "variables = [\n",
    "    ('Logistic Regression', logistic_reg),\n",
    "    ('Naive Bayes', naive_bayes),\n",
    "    ('Decision Tree', decision_tree),\n",
    "    ('k-Nearest Neighbors', k_nearest),\n",
    "    ('Support Vector Machines', support_vector)\n",
    "]\n",
    "table = PrettyTable()\n",
    "table.add_column('Algorithm', labels)\n",
    "table.add_column('Logistic Regression', logistic_reg)\n",
    "table.add_column('Naive Bayes', naive_bayes)\n",
    "table.add_column('Decision Tree', decision_tree)\n",
    "table.add_column('k-Nearest Neighbors', k_nearest)\n",
    "table.add_column('Support Vector Machines', support_vector)\n",
    "table.align = 'l'\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
